{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw-week09-group27.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 09 â€” IANNwTF\n",
        "## Group 27\n",
        "Deadline: Jan 16, 2021 23:59\n",
        "\n",
        "<https://forms.gle/n6ERdhYx3uBPzuGn9>\n"
      ],
      "metadata": {
        "id": "2Qaj18msKDOK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "sd37kIBGJ8-U"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Quick, Draw! Dataset"
      ],
      "metadata": {
        "id": "qf7u6G_YeN1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "\n",
        "from IPython import display"
      ],
      "metadata": {
        "id": "M4X2hjL1eRSz"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "categories = [line.rstrip(b'\\n') for line in urllib.request.urlopen('https://raw.githubusercontent.com/googlecreativelab/quickdraw-dataset/master/categories.txt')]\n",
        "print(categories[:10])\n",
        "category = 'candle'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyVButk1eUGv",
        "outputId": "c64b832f-b929-4eac-89a8-ad5b72d95d09"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[b'aircraft carrier', b'airplane', b'alarm clock', b'ambulance', b'angel', b'animal migration', b'ant', b'anvil', b'apple', b'arm']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates a folder to download the original drawings into.\n",
        "# We chose to use the numpy format : 1x784 pixel vectors, with values going from 0 (white) to 255 (black). We reshape them later to 28x28 grids and normalize the pixel intensity to [-1, 1]\n",
        "\n",
        "if not os.path.isdir('npy_files'):\n",
        "    os.mkdir('npy_files')\n",
        "    \n",
        "url = f'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/{category}.npy'  \n",
        "urllib.request.urlretrieve(url, f'npy_files/{category}.npy')\n",
        "\n",
        "images = np.load(f'npy_files/{category}.npy')\n",
        "print(f'{len(images)} images available')\n",
        "\n",
        "# You can limit the amount of images you use for training by setting :\n",
        "train_images = images[:10000]\n",
        "# You should also define a samller subset of the images for testing..\n",
        "test_images = images[100000:]\n",
        "\n",
        "print()\n",
        "print(f'{len(train_images)} images used for training')\n",
        "print(f'{len(test_images)} images used for testing')\n",
        "\n",
        "\n",
        "# Notice that this to numpy format contains 1x784 pixel vectors, with values going from 0 (white) to 255 (black). We reshape them later to 28x28 grids and normalize the pixel intensity to [-1, 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxTw2KjIeWE2",
        "outputId": "f2917eef-9667-4d2a-b5be-cfc8898f28a7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "141545 images available\n",
            "\n",
            "10000 images used for training\n",
            "41545 images used for testing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show example images\n",
        "npics = 5\n",
        "fig, ax = plt.subplots(nrows=1, ncols=npics, figsize=(15,3))\n",
        "ax = ax.flatten()\n",
        "for i in range(5):\n",
        "    ax[i].imshow(np.reshape(train_images[i], (28, 28)), cmap='gray', vmin=0, vmax=255)\n",
        "    ax[i].axis(\"off\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "Lide4TqhhIWv",
        "outputId": "b6df827e-bde6-4e52-9575-e912b7d924b8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x216 with 5 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "pytsUrBwKYea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(image_array):\n",
        "\n",
        "  # create dataset from array\n",
        "  ds = tf.data.Dataset.from_tensor_slices(image_array)\n",
        "  # cast tensors to float32\n",
        "  ds = ds.map(lambda img: tf.cast(img, tf.float32))\n",
        "  # reshape the pixel arrays to images\n",
        "  ds = ds.map(lambda img: tf.reshape(img, (28,28,1)))\n",
        "  # normalize (bring values to a range from -1 to 1)\n",
        "  ds = ds.map(lambda img: ((img/128.)-1.))\n",
        "  # shuffle, batch, prefetch\n",
        "  ds = ds.shuffle(1000).batch(32).prefetch(20)\n",
        "\n",
        "  return ds\n"
      ],
      "metadata": {
        "id": "eZC3DWYzfnEn"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = prepare_data(train_images)\n",
        "test_ds = prepare_data(test_images)"
      ],
      "metadata": {
        "id": "w4rcURbQfVaQ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model: GAN"
      ],
      "metadata": {
        "id": "S_AaJR8jkCoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.layers_1 = [# first convolution\n",
        "                     tf.keras.layers.Conv2D(16, (3,3), activation='relu', padding='same', input_shape=(28, 28, 1)),\n",
        "                     tf.keras.layers.Dropout(0.3)]\n",
        "    self.bn_1 = tf.keras.layers.BatchNormalization()\n",
        "    self.layers_2 = [tf.keras.layers.MaxPooling2D(2, 2),\n",
        "                     # second convolution\n",
        "                      tf.keras.layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
        "                      tf.keras.layers.Dropout(0.3)]\n",
        "    self.bn_2 = tf.keras.layers.BatchNormalization()\n",
        "    self.layers_3 = [tf.keras.layers.MaxPooling2D(2, 2),\n",
        "                     # third convolution\n",
        "                      tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
        "                      tf.keras.layers.Dropout(0.3)]\n",
        "    self.bn_3 = tf.keras.layers.BatchNormalization()\n",
        "    self.layers_4 = [tf.keras.layers.MaxPooling2D(2,2),\n",
        "                     # flatten, dense, output\n",
        "                    tf.keras.layers.Flatten(),\n",
        "                    tf.keras.layers.Dense(512, activation='relu'),\n",
        "                    tf.keras.layers.Dense(1, activation='sigmoid')]\n",
        "  \n",
        "  def call(self, x, training=True):\n",
        "    for layer in self.layers_1:\n",
        "      x = layer(x)\n",
        "    x = self.bn_1(x, training = training)\n",
        "    for layer in self.layers_2:\n",
        "      x = layer(x)\n",
        "    x = self.bn_2(x, training = training)\n",
        "    for layer in self.layers_3:\n",
        "      x = layer(x)\n",
        "    x = self.bn_3(x, training = training)\n",
        "    for layer in self.layers_4:\n",
        "      x = layer(x)\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "I3xCHM3jkC6M"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Generator, self).__init__()\n",
        "    self.layers_list = []\n",
        "\n",
        "  \n",
        "  def call(self, x):\n",
        "    for layer in self.layers_list:\n",
        "      x = layer(x)\n",
        "    return x\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AUAmIuqb2-ex"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "L2L0O8Aqpm_9"
      }
    }
  ]
}